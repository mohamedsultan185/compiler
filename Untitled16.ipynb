{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2c9d7ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword\n",
      "special character\n",
      "identifier\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class KeywordDetector:\n",
    "    keywords = {\n",
    "        \"abstract\", \"assert\", \"boolean\", \"break\", \"byte\", \"case\", \"catch\", \"char\", \"class\",\n",
    "        \"const\", \"continue\", \"default\", \"double\", \"do\", \"else\", \"enum\", \"extends\", \"final\",\n",
    "        \"finally\", \"float\", \"for\", \"goto\", \"if\", \"implements\", \"import\", \"instanceof\", \"int\",\n",
    "        \"interface\", \"long\", \"native\", \"new\", \"package\", \"private\", \"protected\", \"public\",\n",
    "        \"return\", \"short\", \"static\", \"strictfp\", \"super\", \"switch\", \"synchronized\", \"this\",\n",
    "        \"throw\", \"throws\", \"transient\", \"try\", \"void\", \"volatile\", \"while\"\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def detect(s):\n",
    "        lower_case_str = s.lower()\n",
    "        special_characters = \"!@#$%^&*()-_=+[]{}|;:,.<>?/`~\"\n",
    "        pattern = re.compile(\"[a-zA-Z_][a-zA-Z0-9_]*\")\n",
    "\n",
    "        if lower_case_str in KeywordDetector.keywords:\n",
    "            return \"keyword\"\n",
    "        elif any(char in special_characters for char in s):\n",
    "            return \"special character\"\n",
    "        elif pattern.match(lower_case_str):\n",
    "            return \"identifier\"\n",
    "        else:\n",
    "            return \"combination of keyword, special character, and/or identifier\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(KeywordDetector.detect(\"public\"))  \n",
    "    print(KeywordDetector.detect(\"!\"))      \n",
    "    print(KeywordDetector.detect(\"name\"))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbec656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse Result: ('-', ('+', 2, 3), 1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class SyntaxAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.current_token = None\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def set_tokenizer(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.advance()\n",
    "\n",
    "    def advance(self):\n",
    "        self.current_token = self.tokenizer.get_next_token()\n",
    "\n",
    "    def error(self, message):\n",
    "        raise SyntaxError(f\"Syntax Error: {message}\")\n",
    "\n",
    "    def term(self):\n",
    "        \"\"\"\n",
    "        Parses a term: factor ((PLUS | MINUS) factor)*\n",
    "        \"\"\"\n",
    "        result = self.factor()\n",
    "\n",
    "        while self.current_token in {'+', '-'}:\n",
    "            operator = self.current_token\n",
    "            self.advance()\n",
    "            right = self.factor()\n",
    "\n",
    "            if operator == '+':\n",
    "                result = ('+', result, right)\n",
    "            else:\n",
    "                result = ('-', result, right)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def factor(self):\n",
    "        \"\"\"\n",
    "        Parses a factor: INTEGER\n",
    "        \"\"\"\n",
    "        token = self.current_token\n",
    "\n",
    "        if re.match(r\"\\d+\", token):\n",
    "            self.advance()\n",
    "            return int(token)\n",
    "        else:\n",
    "            self.error(\"Expected an integer\")\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        Parses the input using the defined grammar rules.\n",
    "        \"\"\"\n",
    "        return self.term()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    class Tokenizer:\n",
    "        def __init__(self, input_string):\n",
    "            self.tokens = re.findall(r\"\\d+|[+\\\\-]\", input_string)\n",
    "            self.current_index = 0\n",
    "\n",
    "        def get_next_token(self):\n",
    "            if self.current_index < len(self.tokens):\n",
    "                token = self.tokens[self.current_index]\n",
    "                self.current_index += 1\n",
    "                return token\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    input_expression = \"2 + 3 - 1\"\n",
    "    tokenizer = Tokenizer(input_expression)\n",
    "    \n",
    "    syntax_analyzer = SyntaxAnalyzer()\n",
    "    syntax_analyzer.set_tokenizer(tokenizer)\n",
    "\n",
    "    result = syntax_analyzer.parse()\n",
    "    print(\"Parse Result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b75ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
